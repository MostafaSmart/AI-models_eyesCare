{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow imagehash\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWeoxBUkl-pu",
        "outputId": "8711e94d-f1a7-4c66-c60d-a52b964fc6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting PyWavelets (from imagehash)\n",
            "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.13.1)\n",
            "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets, imagehash\n",
            "Successfully installed PyWavelets-1.7.0 imagehash-4.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2sFX6dQUIq5"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"SFJrAVaaXyD61wxYQ4wn\")\n",
        "project = rf.workspace(\"eyescareworkspace\").project(\"eyedisease-3tnz0-hk8h0\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf = Roboflow(api_key=\"Mw0WRYo7QKz4vlBJWxWG\")\n",
        "project = rf.workspace(\"eyezsmartdet\").project(\"alltheimaegs\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfnpADcqsRXZ",
        "outputId": "7b76dd62-b94a-4d92-fd6f-13b4b480bc43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.196`, to intall it `pip install ultralytics==8.0.196`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in allTheImaegs-1 to yolov8:: 100%|██████████| 69142/69142 [00:01<00:00, 48959.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to allTheImaegs-1 in yolov8:: 100%|██████████| 3530/3530 [00:00<00:00, 3550.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import display,Image\n",
        "import cv2\n",
        "base_folder_path = '/content/allTheImaegs-1'\n",
        "\n",
        "main_folders = ['train', 'test', 'valid']\n",
        "counts_per_folder = {}\n",
        "\n",
        "# احسب الإحصائيات\n",
        "for folder in main_folders:\n",
        "    label_folder_path = os.path.join(base_folder_path, folder, 'labels')\n",
        "\n",
        "    files = [f for f in os.listdir(label_folder_path) if f.endswith('.txt')]\n",
        "\n",
        "    numbers = []\n",
        "\n",
        "    for file in files:\n",
        "        with open(os.path.join(label_folder_path, file), 'r') as f:\n",
        "            for line in f:\n",
        "                first_number = line.split()[0]\n",
        "                numbers.append(int(first_number))\n",
        "                break\n",
        "\n",
        "    counter = Counter(numbers)\n",
        "    counts_per_folder[folder] = counter\n",
        "\n",
        "# اطبع الإحصائيات كتابياً\n",
        "for folder, counter in counts_per_folder.items():\n",
        "    print(f\"Statistics for {folder}:\")\n",
        "    for cls, count in sorted(counter.items()):\n",
        "        print(f\"Class {cls}: {count}\")\n",
        "    print()\n",
        "\n",
        "# تحضير البيانات للتمثيل البياني\n",
        "all_classes = sorted(set(key for counter in counts_per_folder.values() for key in counter.keys()))\n",
        "bar_width = 0.2\n",
        "indices = np.arange(len(all_classes))\n",
        "\n",
        "colors = ['blue', 'yellow', 'red']\n",
        "\n",
        "# رسم الرسوم البيانية\n",
        "for i, folder in enumerate(main_folders):\n",
        "    counter = counts_per_folder[folder]\n",
        "    values = [counter.get(cls, 0) for cls in all_classes]\n",
        "    plt.bar(indices + i * bar_width, values, color=colors[i], width=bar_width, label=folder)\n",
        "\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Numbers')\n",
        "plt.title('Dataset Statistics')\n",
        "plt.xticks(indices + bar_width, all_classes)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LUMBJhTWe9it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf = Roboflow(api_key=\"MY_API_KEY\")\n",
        "project = rf.workspace(\"eyezsmartdet\").project(\"conjunctivitis\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex4kJcmptpqX",
        "outputId": "4c78be74-a374-4a27-ad4c-e3d24fc667e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.196`, to intall it `pip install ultralytics==8.0.196`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in conjunctivitis-1 to yolov8:: 100%|██████████| 14246/14246 [00:00<00:00, 46629.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to conjunctivitis-1 in yolov8:: 100%|██████████| 700/700 [00:00<00:00, 5466.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf = Roboflow(api_key=\"MY_API_KEY\")\n",
        "project = rf.workspace(\"eyezsmartdet\").project(\"conjunctivitis\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g1UEV89ACim",
        "outputId": "e26aea2a-ea90-4f04-fbef-681c362b3af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.196`, to intall it `pip install ultralytics==8.0.196`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in conjunctivitis-3 to yolov8:: 100%|██████████| 25413/25413 [00:00<00:00, 31140.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to conjunctivitis-3 in yolov8:: 100%|██████████| 1246/1246 [00:00<00:00, 2671.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r normal.zip /content/normal"
      ],
      "metadata": {
        "id": "FxrSlySesm2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h normal.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhjiSEa6tKma",
        "outputId": "fbfd2fcc-f19b-4ebc-d623-0ec37719159b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17M\tnormal.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# القاموس الذي يحتوي على أسماء المجلدات لكل تصنيف\n",
        "class_mapping = {\n",
        "    \"0\": \"catract\",\n",
        "    \"1\": \"conjunctivitis\",\n",
        "    \"2\": \"normal\",\n",
        "    \"3\": \"pterygium\",\n",
        "    \"4\": \"stye\"\n",
        "}\n",
        "\n",
        "# دالة لنقل الصور إلى المجلدات بناءً على تصنيفات ملفات .txt\n",
        "def sort_images_by_label(images_folder, labels_folder, output_folder):\n",
        "    # التأكد من وجود مجلد الإخراج\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # المرور على جميع ملفات .txt في مجلد labels\n",
        "    for label_file in os.listdir(labels_folder):\n",
        "        if label_file.endswith('.txt'):\n",
        "            label_path = os.path.join(labels_folder, label_file)\n",
        "\n",
        "            # قراءة محتويات ملف .txt لاستخراج التصنيف\n",
        "            with open(label_path, 'r') as f:\n",
        "                label = f.readline().split()[0]  # استخراج أول رقم (التصنيف)\n",
        "\n",
        "                # التحقق من أن التصنيف موجود في القاموس\n",
        "                if label in class_mapping:\n",
        "                    category = class_mapping[label]\n",
        "\n",
        "                    # مسار مجلد التصنيف\n",
        "                    category_folder = os.path.join(output_folder, category)\n",
        "\n",
        "                    # إنشاء مجلد التصنيف إذا لم يكن موجودًا\n",
        "                    if not os.path.exists(category_folder):\n",
        "                        os.makedirs(category_folder)\n",
        "\n",
        "                    # مطابقة اسم ملف الصورة مع اسم ملف .txt بأي امتداد ممكن\n",
        "                    image_base = label_file.replace('.txt', '')\n",
        "                    image_path_jpg = os.path.join(images_folder, image_base + '.jpg')\n",
        "                    image_path_png = os.path.join(images_folder, image_base + '.png')\n",
        "\n",
        "                    # التحقق من أن الصورة موجودة بامتداد .jpg أو .png\n",
        "                    if os.path.exists(image_path_jpg):\n",
        "                        shutil.copy(image_path_jpg, category_folder)\n",
        "                        print(f\"Copied {image_base}.jpg to {category_folder}\")\n",
        "                    elif os.path.exists(image_path_png):\n",
        "                        shutil.copy(image_path_png, category_folder)\n",
        "                        print(f\"Copied {image_base}.png to {category_folder}\")\n",
        "                    else:\n",
        "                        print(f\"Image {image_base} not found with .jpg or .png extension.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3GaAbQFTlVXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# مسارات المجلدات\n",
        "images_folder = '/content/allTheImaegs-1/test/images'\n",
        "labels_folder = '/content/allTheImaegs-1/test/labels'\n",
        "output_folder = 'nnnnnnnnnnnnnn/test'  # مجلد الإخراج حيث سيتم إنشاء المجلدات التصنيفية\n",
        "\n",
        "# تنفيذ الفرز\n",
        "sort_images_by_label(images_folder, labels_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "kvNTmp1VldiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "rbleACGLxPtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def copyTextAndImage(foldar_imaegs,folder_labels,destention_images,destention_labels):\n",
        "\n",
        "  images_names = os.listdir(foldar_imaegs)\n",
        "\n",
        "  if not os.path.exists(destention_images):\n",
        "    os.makedirs(destention_images)\n",
        "  if not os.path.exists(destention_labels):\n",
        "    os.makedirs(destention_labels)\n",
        "\n",
        "\n",
        "\n",
        "  for name in images_names:\n",
        "\n",
        "    base_name = Path(name).stem\n",
        "    label_name = f'{base_name}.txt'\n",
        "\n",
        "    imag_path = os.path.join(foldar_imaegs,name)\n",
        "    label_path = os.path.join(folder_labels,label_name)\n",
        "\n",
        "    img_dest = os.path.join(destention_images,name)\n",
        "    label_dest = os.path.join(destention_labels,label_name)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    shutil.copyfile(imag_path,img_dest)\n",
        "    shutil.copyfile(label_path,label_dest)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lQszKt_nu2nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foldar_imaegs = '/content/nnnnnnnnnnnnnn/train/pterygium'\n",
        "folder_labels = '/content/allTheImaegs-1/train/labels'\n",
        "\n",
        "destention_images = 'wwwwwwwwwwwwwwwww/train/images'\n",
        "destention_labels = 'wwwwwwwwwwwwwwwww/train/labels'\n",
        "\n",
        "copyTextAndImage(foldar_imaegs,folder_labels,destention_images,destention_labels)\n"
      ],
      "metadata": {
        "id": "lwv2CwP6ya9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destention_images = 'normalnormal/train/images'\n",
        "destention_labels = 'normalnormal/train/labels'\n"
      ],
      "metadata": {
        "id": "cyrqkOnZ0LHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(destention_images)),len(os.listdir(destention_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ABfEe26ydxJ",
        "outputId": "7a7577a7-4e02-4208-ff2e-a5fc1026b090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(595, 595)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "\n",
        "# دالة لحساب الهاش لكل صورة في المجلد\n",
        "def calculate_hashes(folder_path):\n",
        "    hashes = {}\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            # فتح الصورة وحساب الهاش\n",
        "            image = Image.open(file_path)\n",
        "            hash_value = imagehash.phash(image)  # يمكنك تغيير phash إلى dhash أو ahash حسب رغبتك\n",
        "            hashes[filename] = hash_value\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "    return hashes\n",
        "\n",
        "# دالة لاكتشاف الصور المكررة بين المجلدين وحذف المكررات من المجلد الأول\n",
        "def find_and_delete_duplicate_images(folder1, folder2,other):\n",
        "    folder1_hashes = calculate_hashes(folder1)\n",
        "    folder2_hashes = calculate_hashes(folder2)\n",
        "\n",
        "    duplicates = []\n",
        "\n",
        "    # مقارنة الهاش لكل صورة في المجلد الأول مع كل الصور في المجلد الثاني\n",
        "    for file1, hash1 in folder1_hashes.items():\n",
        "        for file2, hash2 in folder2_hashes.items():\n",
        "            if hash1 == hash2:\n",
        "                duplicates.append((file1, file2))\n",
        "\n",
        "                # حذف الصورة من المجلد الأول\n",
        "                file1_path = os.path.join(folder1, file1)\n",
        "                if not os.path.exists(other):\n",
        "                        os.makedirs(other)\n",
        "                try:\n",
        "                    shutil.move(file1_path,f'{other}/{file1}')\n",
        "                    print(f\"moveed {file1} from {folder1}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error deleting {file1}: {e}\")\n",
        "\n",
        "    return duplicates\n"
      ],
      "metadata": {
        "id": "KNvWmWsJlwVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# مسارات المجلدين\n",
        "folder1_path = '/content/train/stye'\n",
        "folder2_path = '/content/valid/stye'\n",
        "\n",
        "# العثور على الصور المكررة وحذفها من المجلد الأول\n",
        "duplicate_images = find_and_delete_duplicate_images(folder1_path, folder2_path,'catractOther')\n",
        "\n",
        "if duplicate_images:\n",
        "    print(\"Found and deleted duplicate images:\")\n",
        "    for img1, img2 in duplicate_images:\n",
        "        print(f\"{img1} is a duplicate of {img2}\")\n",
        "else:\n",
        "    print(\"No duplicate images found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR57PnjXmJt4",
        "outputId": "de10b1e0-bdba-4b0f-8d47-6d0eea92e533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "moveed stye-36-_jpg.rf.e0701f8c30247f4775c52d00038e4545.jpg from /content/train/stye\n",
            "moveed stye-144-_jpg.rf.e74558a0b204241677dd3a2463459157.jpg from /content/train/stye\n",
            "moveed stye-246-_jpg.rf.c91dcf88548cde5754b4a275adc20380.jpg from /content/train/stye\n",
            "Found and deleted duplicate images:\n",
            "stye-36-_jpg.rf.e0701f8c30247f4775c52d00038e4545.jpg is a duplicate of stye-258-_jpg.rf.8c6a3e977ad9231970ed05ab30b64108.jpg\n",
            "stye-144-_jpg.rf.e74558a0b204241677dd3a2463459157.jpg is a duplicate of 240_F_349854363_7FqBNULufmHDZnAYYA7Qa1c4H9afhL1e_jpg.rf.8bc98f6066f6663fe9337202d296a475.jpg\n",
            "stye-246-_jpg.rf.c91dcf88548cde5754b4a275adc20380.jpg is a duplicate of 240_F_349854363_7FqBNULufmHDZnAYYA7Qa1c4H9afhL1e_jpg.rf.8bc98f6066f6663fe9337202d296a475.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "\n",
        "# دالة لحساب الهاش لكل صورة في المجلد\n",
        "def calculate_hashes(folder_path):\n",
        "    hashes = {}\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            # فتح الصورة وحساب الهاش\n",
        "            image = Image.open(file_path)\n",
        "            hash_value = imagehash.phash(image)  # يمكنك تغيير phash إلى dhash أو ahash حسب رغبتك\n",
        "            hashes[filename] = hash_value\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "    return hashes\n",
        "\n",
        "# دالة لاكتشاف الصور المكررة بين المجلدين\n",
        "def find_duplicate_images(folder1, folder2):\n",
        "    folder1_hashes = calculate_hashes(folder1)\n",
        "    folder2_hashes = calculate_hashes(folder2)\n",
        "\n",
        "    duplicates = []\n",
        "\n",
        "    # مقارنة الهاش لكل صورة في المجلد الأول مع كل الصور في المجلد الثاني\n",
        "    for file1, hash1 in folder1_hashes.items():\n",
        "        for file2, hash2 in folder2_hashes.items():\n",
        "            if hash1 == hash2:\n",
        "                duplicates.append((file1, file2))\n",
        "\n",
        "    return duplicates\n",
        "\n"
      ],
      "metadata": {
        "id": "9tALATtRoj2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# مسارات المجلدين\n",
        "folder1_path = 'dataset/train/images'\n",
        "folder2_path = 'dataset/valid/images'\n",
        "\n",
        "# العثور على الصور المكررة وحذفها من المجلد الأول\n",
        "duplicate_images = find_duplicate_images(folder1_path, folder2_path)\n",
        "\n",
        "if duplicate_images:\n",
        "    print(\"Found and deleted duplicate images:\")\n",
        "    for img1, img2 in duplicate_images:\n",
        "        print(f\"{img1} is a duplicate of {img2}\")\n",
        "else:\n",
        "    print(\"No duplicate images found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jPtDyulomjh",
        "outputId": "1365c420-e69b-437c-f553-ceb3d0332b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No duplicate images found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r all_labels.zip /content/EyeDisease-1/train/labels"
      ],
      "metadata": {
        "id": "eyTbI7TP1STw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h all_labels.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxqT9ToR1ciZ",
        "outputId": "177058f3-7f2b-45b4-9667-08113efef260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "696K\tall_labels.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dd.zip -d ccov"
      ],
      "metadata": {
        "id": "GxbXN9nnEVPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "rf = Roboflow(api_key='MY_API_KEY')\n",
        "\n",
        "# get a workspace\n",
        "workspace = rf.workspace(\"eyescareworkspace\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaEKGncZ3ig3",
        "outputId": "bb558cde-6f42-465a-b188-dd0aecb45692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rloading Roboflow workspace...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload data set to a new/existing project\n",
        "workspace.upload_dataset(\n",
        "    \"/content/wwwwwwwwwwwwwwwww\", # This is your dataset path\n",
        "    \"threeclassonly\", # This will either create or get a dataset with the given ID\n",
        "    num_workers=10,\n",
        "\n",
        "    project_type=\"object-detection\",\n",
        "    batch_name=None,\n",
        "    num_retries=0\n",
        ")"
      ],
      "metadata": {
        "id": "nuNyNOfM33P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/test/catract'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnfsqIlKPNNH",
        "outputId": "d637cb47-f1ab-47a9-b73b-4015e0cacee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/train/catract'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acu9R17jPRV1",
        "outputId": "138c550a-c590-4c44-c9c6-fd36115f1708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "361"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/valid/catract'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU99o4rJPS-Q",
        "outputId": "934f0a98-ca65-450e-e6b5-1318e9acad93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    }
  ]
}